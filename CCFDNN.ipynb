{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,random_split,TensorDataset\n",
    "from torchvision import datasets,transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 227451 \n",
      " 227451 227451\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\saipr\\Downloads\\creditcard.csv\\creditcard.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df.drop('Time',axis=1,inplace=True)\n",
    "x=df.drop(columns=['Class'])\n",
    "y=df['Class']\n",
    "#print(y.shape,x.shape)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,random_state=42)\n",
    "smote=SMOTE(random_state=2)\n",
    "x_train_smote,y_train_smote=smote.fit_resample(x_train,y_train)\n",
    "print(sum(y_train==1),sum(y_train==0),\"\\n\",sum(y_train_smote==1),sum(y_train_smote==0))\n",
    "x_train_smote=torch.tensor(np.array(x_train_smote),dtype=torch.float32)\n",
    "y_train_smote=torch.tensor(np.array(y_train_smote),dtype=torch.int64)\n",
    "x_train=torch.tensor(np.array(x_train),dtype=torch.float32)\n",
    "x_test=torch.tensor(np.array(x_test),dtype=torch.float32)\n",
    "y_train=torch.tensor(np.array(y_train),dtype=torch.int64)\n",
    "y_test=torch.tensor(np.array(y_test),dtype=torch.int64)\n",
    "train_data_smote=TensorDataset(x_train_smote,y_train_smote)\n",
    "train_loader_smote=DataLoader(train_data_smote,batch_size=64,shuffle=True)\n",
    "train_data=TensorDataset(x_train,y_train)\n",
    "test_data=TensorDataset(x_test,y_test)\n",
    "train_loader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self,input_size=29,output_size=2):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(input_size,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NN()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimiser=optim.Adam(model.parameters(),lr=1e-3)\n",
    "model_smote=NN()\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This output is on training data which is after smoting the data\n",
      "Loss in epoch [1/20]:0.7091937065124512\n",
      "Loss in epoch [2/20]:0.7155966758728027\n",
      "Loss in epoch [3/20]:0.687050998210907\n",
      "Loss in epoch [4/20]:0.7150242328643799\n",
      "Loss in epoch [5/20]:0.7029466032981873\n",
      "Loss in epoch [6/20]:0.6896953582763672\n",
      "Loss in epoch [7/20]:0.6840416193008423\n",
      "Loss in epoch [8/20]:0.6968116164207458\n",
      "Loss in epoch [9/20]:0.702636182308197\n",
      "Loss in epoch [10/20]:0.7092267274856567\n",
      "Loss in epoch [11/20]:0.6900562047958374\n",
      "Loss in epoch [12/20]:0.6967028379440308\n",
      "Loss in epoch [13/20]:0.6897612810134888\n",
      "Loss in epoch [14/20]:0.7215195894241333\n",
      "Loss in epoch [15/20]:0.7029429078102112\n",
      "Loss in epoch [16/20]:0.6871228218078613\n",
      "Loss in epoch [17/20]:0.7093034386634827\n",
      "Loss in epoch [18/20]:0.7000370621681213\n",
      "Loss in epoch [19/20]:0.7183034420013428\n",
      "Loss in epoch [20/20]:0.702218234539032\n"
     ]
    }
   ],
   "source": [
    "print('This output is on training data which is after smoting the data')\n",
    "for epoch in range(num_epochs):\n",
    "    for input,output in train_loader_smote:\n",
    "        pred_out=model_smote(input)\n",
    "        # print(pred_out.size())\n",
    "        loss=criterion(pred_out,output)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(f'Loss in epoch [{epoch+1}/{num_epochs}]:{loss}')\n",
    "    if loss<10e-07:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch [1/20]:0.022506870329380035\n",
      "Loss in epoch [2/20]:0.0043348162434995174\n",
      "Loss in epoch [3/20]:0.001961809117347002\n",
      "Loss in epoch [4/20]:0.0016750365030020475\n",
      "Loss in epoch [5/20]:0.0018130785319954157\n",
      "Loss in epoch [6/20]:0.001731921685859561\n",
      "Loss in epoch [7/20]:0.0017503669951111078\n",
      "Loss in epoch [8/20]:0.0017673838883638382\n",
      "Loss in epoch [9/20]:0.0016707520699128509\n",
      "Loss in epoch [10/20]:0.0017010994488373399\n",
      "Loss in epoch [11/20]:0.0016975293401628733\n",
      "Loss in epoch [12/20]:0.0017573880031704903\n",
      "Loss in epoch [13/20]:0.001696815132163465\n",
      "Loss in epoch [14/20]:0.001733230659738183\n",
      "Loss in epoch [15/20]:0.001768692978657782\n",
      "Loss in epoch [16/20]:0.0017077637603506446\n",
      "Loss in epoch [17/20]:0.0017268045339733362\n",
      "Loss in epoch [18/20]:0.001774523756466806\n",
      "Loss in epoch [19/20]:0.0017876134952530265\n",
      "Loss in epoch [20/20]:0.0017303746426478028\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for input,output in train_loader:\n",
    "        pred_out=model(input)\n",
    "        # print(pred_out.size())\n",
    "        loss=criterion(pred_out,output)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(f'Loss in epoch [{epoch+1}/{num_epochs}]:{loss}')\n",
    "    if loss<10e-07:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy report of <torch.utils.data.dataloader.DataLoader object at 0x00000208E09C1F70>:\n",
      "Non Fraud:[227341/227451]\n",
      "Fraud:[0/227451]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67    227451\n",
      "           1       0.00      0.00      0.00    227451\n",
      "\n",
      "    accuracy                           0.50    454902\n",
      "   macro avg       0.25      0.50      0.33    454902\n",
      "weighted avg       0.25      0.50      0.33    454902\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model,dataloader,classes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test,y_pred=[],[]\n",
    "        for input,output in dataloader:\n",
    "            pred_output=model(input)\n",
    "            y_test.extend(output.numpy())\n",
    "            y_pred.extend(torch.argmax(pred_output,dim=1).numpy())\n",
    "        #classes=dataloader.classes\n",
    "        cor,tot=[],[]\n",
    "        for i in range(len(classes)):\n",
    "            cor.append(sum(1 for j,k in zip(y_test,y_pred) if j==i and k==i))\n",
    "            tot.append(sum (1 for j in y_test if j==i))\n",
    "        print(f'accuracy report of {dataloader}:')\n",
    "        for i,cl in enumerate(classes):\n",
    "            print(f'{cl}:[{cor[i]}/{tot[i]}]')\n",
    "        print(classification_report(y_test,y_pred))\n",
    "    model.train()\n",
    "print(accuracy(model_smote,train_loader_smote,['Non Fraud','Fraud']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
